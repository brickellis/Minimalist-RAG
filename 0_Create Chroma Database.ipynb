{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Save .txt as a Chroma vector database with embeddings generated by all-MiniLM-L6-v2\n",
        "'''\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "history.txt: The Beginner's American History by D. H. Montgomery\n",
        "'''\n",
        "file_name = \"history\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Create a text splitter to split the .txt into chunks of 500 characters apiece. The chunks overlap by 100 characters \n",
        "to prevent valuable information from being split between two chunks.\n",
        "\n",
        "Embeddings Model: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
        "'''\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap  = 100,\n",
        ")\n",
        "\n",
        "embeddings_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Create LangChain documents for the chunks as they are split.\n",
        "Since it seems faster to load data into a ChromaDB piecewise, split\n",
        "the list of docs into a list of lists with 1000 docs each.\n",
        "'''\n",
        "with open(file_name + '.txt', 'r') as source_file:\n",
        "    source = source_file.read()\n",
        "\n",
        "docs = text_splitter.create_documents([source])\n",
        "docs_len = len(docs)\n",
        "print(docs_len)\n",
        "sublist_length = 1000\n",
        "docs_split = [docs[i:i + sublist_length] for i in range(0, len(docs), sublist_length)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Load the docs into the vectorstore and persist it (create files \n",
        "which can be accessed later instead of keeping it all in memory)\n",
        "\n",
        "Note that if this code is run again, it'll add to the existing vectorstore instead of replacing it,\n",
        "which can create duplicates or unintentionally retain old data.\n",
        "If you want to create a different vectorstore after creating one, either remove the existing one or\n",
        "change the name for the new one. It is also smart to restart the python kernel to clear\n",
        "your old vectorstore from your memory.\n",
        "'''\n",
        "completed_docs = 0\n",
        "if 'vectordb' not in locals() and 'vectordb' not in globals():\n",
        "    for docs in docs_split:\n",
        "        completed_docs += len(docs)\n",
        "        print(str(completed_docs) + ' / ' + str(docs_len))\n",
        "        vectordb = Chroma.from_documents(documents=docs, embedding=embeddings_model, persist_directory=file_name + '_db')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNyvtC67lt0rjksvsVD/bdI",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
